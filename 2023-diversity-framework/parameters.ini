[CDL]
tune_parameters = lambda_u,lambda_v
lambda_u = 0.01,0.1,1,10,100,1000
lambda_v = 0.01,0.1,1,10,100,1000
k = 50
max_iter = 30
lambda_w = 0.1
lambda_n = 1000
seed = 123

[CTR]
tune_parameters = k,lambda_u,lambda_v
k = 20,40,60,100,200
lambda_v = 0.01,0.1,1,10,100,1000
lambda_u = 0.01,0.1,1,10,100,1000
eta = 0.01
a = 1
b = 0.01
max_iter = 50
seed = 123

[HFT]
tune_parameters = k
k = 10, 100, 200, 300, 400
max_iter = 40
grad_iter = 5
l2_reg = 0.001
lambda_text = 0.01
vocab_size = 8000
seed = 123

[ConvMF]
tune_parameters = k,lambda_u,lambda_v
lambda_u = 0.01,0.1,1,10,100,1000
lambda_v = 0.01,0.1,1,10,100,1000
k = 300
n_epochs = 50
cnn_epochs = 5
seed = 123

[CDR]
tune_parameters = lambda_u,lambda_v
lambda_u = 0.01,0.1,1,10,100,1000
lambda_v = 0.01,0.1,1,10,100,1000
k = 50
max_iter = 100
batch_size = 128
lambda_w = 0.0001
lambda_n = 5
learning_rate = 0.001
vocab_size = 8000
seed = 123

[CVAE]
tune_parameters = lambda_u,lambda_v
lambda_u = 0.01,0.1,1,10,100,1000
lambda_v = 0.01,0.1,1,10,100,1000
z_dim = 50
act_fn = sigmoid
input_dim = 8000
lr = 0.001
batch_size = 128
n_epochs = 100
lambda_r = 10
lambda_w = 0.0001
seed = 123

[DAE]
tune_parameters = qk_dims
qk_dims = 20, 200, 600, 1000, 5000
n_epochs = 100
batch_size = 100
learning_rate = 0.001
weight_decay = 0.0
dropout_p = 0.5
seed = 123

[ENMF]
tune_parameters = neg_weight
neg_weight = 0.1, 0.3, 0.5, 0.7, 0.9, 1
lambda_v = 0.1, 1, 10, 100
dropout_p = 0.7
num_epochs = 100
batch_size = 256
lr = 0.05

